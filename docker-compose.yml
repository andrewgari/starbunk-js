version: '3.8'

services:
  # BunkBot - Next generation YAML-based reply bot system
  bunkbot:
    build:
      context: .
      dockerfile: src/bunkbot/Dockerfile
    image: ghcr.io/andrewgari/bunkbot:latest
    container_name: starbunk-bunkbot
    restart: unless-stopped
    env_file:
      - .env
    environment:
      # Required: Discord bot token for BunkBot
      - DISCORD_TOKEN=${BUNKBOT_TOKEN}
      # Required: Discord guild/server ID
      - GUILD_ID=${GUILD_ID}
      - BUNKBOT_BOTS_DIR=/app/config
      # Optional: Internal metrics port (default: 3000)
      - METRICS_PORT=${METRICS_PORT:-3000}
      # OpenTelemetry Configuration (all optional)
      # Optional: OTEL collector hostname (default: otel-collector)
      - OTEL_COLLECTOR_HOST=${OTEL_COLLECTOR_HOST:-otel-collector}
      # Optional: OTEL collector HTTP port (default: 4318)
      - OTEL_COLLECTOR_HTTP_PORT=${OTEL_COLLECTOR_HTTP_PORT:-4318}
      # Optional: Deployment environment (default: production)
      - ENVIRONMENT=${ENVIRONMENT:-production}
      # Optional: Logging level (default: info)
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Mount the bot configuration directory
      - ./config/bunkbot:/app/config:ro
    # No host ports exposed - all observability via OTEL collector
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=bunkbot
      - prometheus.io/scrape=true
      - prometheus.io/path=/metrics
      - prometheus.io/port=3000
      - com.centurylinklabs.watchtower.enable=true
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # DJCova - Music service
  djcova:
    build:
      context: .
      dockerfile: src/djcova/Dockerfile
    image: ghcr.io/andrewgari/djcova:latest
    container_name: starbunk-djcova
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - NODE_ENV=production
      # Optional: Discord bot token (default: STARBUNK_TOKEN)
      - DISCORD_TOKEN=${DJCOVA_TOKEN:-${STARBUNK_TOKEN}}
      # Required: Discord application client ID
      - CLIENT_ID=${DJCOVA_CLIENT_ID}
      # Optional: Enable debug mode (default: false)
      - DEBUG_MODE=${DEBUG_MODE:-false}
      # Optional: Comma-separated testing server IDs (default: empty)
      - TESTING_SERVER_IDS=${TESTING_SERVER_IDS:-}
      # Optional: Comma-separated testing channel IDs (default: empty)
      - TESTING_CHANNEL_IDS=${TESTING_CHANNEL_IDS:-}
      # Optional: Health check port (default: 3000)
      - HEALTH_PORT=${HEALTH_PORT:-3000}
      # OpenTelemetry Configuration (all optional)
      # Optional: OTEL collector hostname (default: starbunk-otel-collector)
      - OTEL_COLLECTOR_HOST=${OTEL_COLLECTOR_HOST:-starbunk-otel-collector}
      # Optional: OTEL collector HTTP port (default: 4318)
      - OTEL_COLLECTOR_HTTP_PORT=${OTEL_COLLECTOR_HTTP_PORT:-4318}
      # Optional: Deployment environment (default: production)
      - ENVIRONMENT=${ENVIRONMENT:-production}
      # Optional: Logging level (default: info)
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Configuration directory (read-only)
      - ./config/djcova:/app/config:ro
      # Data directories (read-write)
      # Optional: Data directory path (default: ./data)
      - ${UNRAID_APPDATA_PATH:-./data}/djcova/cache:/app/cache
      # Optional: Data directory path (default: ./data)
      - ${UNRAID_APPDATA_PATH:-./data}/djcova/temp:/tmp
    # No host ports exposed - all observability via OTEL collector
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=djcova
      - prometheus.io/scrape=true
      - prometheus.io/path=/metrics
      - prometheus.io/port=3000
      - com.centurylinklabs.watchtower.enable=true
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # CovaBot - AI personality bot (Cognitive Simulacrum)
  covabot:
    build:
      context: .
      dockerfile: src/covabot/Dockerfile
    image: ghcr.io/andrewgari/covabot:latest
    container_name: starbunk-covabot
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=--max-old-space-size=768
      # Optional: Discord bot token (default: STARBUNK_TOKEN)
      - DISCORD_TOKEN=${COVABOT_TOKEN:-${STARBUNK_TOKEN}}
      # LLM Configuration (all optional)
      # Optional: OpenAI API key (default: empty, disables OpenAI)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      # Optional: Default OpenAI model (default: gpt-4o-mini)
      - OPENAI_DEFAULT_MODEL=${OPENAI_DEFAULT_MODEL:-gpt-4o-mini}
      # Optional: Ollama API URL (default: empty, disables Ollama)
      - OLLAMA_API_URL=${OLLAMA_API_URL:-}
      # Optional: Default Ollama model (default: mistral:latest)
      - OLLAMA_DEFAULT_MODEL=${OLLAMA_DEFAULT_MODEL:-mistral:latest}
      # Optional: Auto-pull missing Ollama models (default: true)
      - OLLAMA_AUTO_PULL_MODELS=${OLLAMA_AUTO_PULL_MODELS:-true}
      # Optional: Pull Ollama models on startup (default: true)
      - OLLAMA_PULL_ON_STARTUP=${OLLAMA_PULL_ON_STARTUP:-true}
      # Optional: Ollama model pull timeout in ms (default: 1200000 = 20min)
      - OLLAMA_PULL_TIMEOUT_MS=${OLLAMA_PULL_TIMEOUT_MS:-1200000}
      # Redis Configuration (Social Battery) - all optional
      # Optional: Redis hostname (default: host.docker.internal)
      - REDIS_HOST=${REDIS_HOST:-host.docker.internal}
      # Optional: Redis port (default: 6379)
      - REDIS_PORT=${REDIS_PORT:-6379}
      # Optional: Redis password (default: empty)
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      # Optional: Redis database number (default: 0)
      - REDIS_DB=${REDIS_DB:-0}
      # Qdrant Configuration (Saliency/Interest Matching) - all optional
      # Optional: Qdrant URL (default: http://host.docker.internal:6333)
      - QDRANT_URL=${QDRANT_URL:-http://host.docker.internal:6333}
      # Optional: Qdrant API key (default: empty)
      - QDRANT_API_KEY=${QDRANT_API_KEY:-}
      # Storage Configuration
      - COVABOT_DATA_DIR=/app/data
      # Optional: CovaBot API key for web interface (default: empty)
      - COVABOT_API_KEY=${COVABOT_API_KEY:-}
      # Debug/Testing (optional)
      # Optional: Enable debug mode (default: false)
      - DEBUG_MODE=${DEBUG_MODE:-false}
      - HEALTH_PORT=3000
      # OpenTelemetry Configuration (all optional)
      # Optional: OTEL collector hostname (default: otel-collector)
      - OTEL_COLLECTOR_HOST=${OTEL_COLLECTOR_HOST:-otel-collector}
      # Optional: OTEL collector HTTP port (default: 4318)
      - OTEL_COLLECTOR_HTTP_PORT=${OTEL_COLLECTOR_HTTP_PORT:-4318}
      # Optional: Deployment environment (default: production)
      - ENVIRONMENT=${ENVIRONMENT:-production}
      # Optional: Logging level (default: info)
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Configuration directory (read-only)
      - ./config/covabot:/app/config:ro
      # Data directory for personality notes (read-write)
      # Optional: Data directory path (default: ./data)
      - ${UNRAID_APPDATA_PATH:-./data}/covabot:/app/data
    ports:
      # Optional: Web interface port (default: 7080)
      - "${COVABOT_WEB_PORT:-7080}:7080"
      # No metrics port exposed - all observability via OTEL collector
    networks:
      - starbunk-network
    extra_hosts:
      # Required for host.docker.internal to work on Linux
      - "host.docker.internal:host-gateway"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=covabot
      - prometheus.io/scrape=true
      - prometheus.io/path=/metrics
      - prometheus.io/port=3000
      - com.centurylinklabs.watchtower.enable=true
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # BlueBot - Blue detection and response bot
  bluebot:
    build:
      context: .
      dockerfile: src/bluebot/Dockerfile
    image: ghcr.io/andrewgari/bluebot:latest
    container_name: starbunk-bluebot
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - NODE_ENV=production
      # Optional: Discord bot token (default: STARBUNK_TOKEN)
      - DISCORD_TOKEN=${BLUEBOT_TOKEN:-${STARBUNK_TOKEN}}
      - HEALTH_PORT=3000
      # OpenTelemetry Configuration (all optional)
      # Optional: OTEL collector hostname (default: starbunk-otel-collector)
      - OTEL_COLLECTOR_HOST=${OTEL_COLLECTOR_HOST:-starbunk-otel-collector}
      # Optional: OTEL collector HTTP port (default: 4318)
      - OTEL_COLLECTOR_HTTP_PORT=${OTEL_COLLECTOR_HTTP_PORT:-4318}
      # Optional: Deployment environment (default: production)
      - ENVIRONMENT=${ENVIRONMENT:-production}
      # Optional: Logging level (default: info)
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Configuration directory (read-only)
      - ./config/bluebot:/app/config:ro
    # No host ports exposed - all observability via OTEL collector
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=bluebot
      - prometheus.io/scrape=true
      - prometheus.io/path=/metrics
      - prometheus.io/port=3000
      - com.centurylinklabs.watchtower.enable=true
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # OpenTelemetry Collector - Unified telemetry pipeline
  starbunk-otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: starbunk-otel-collector
    restart: unless-stopped
    command: ["--config=/etc/otel-collector-config.yml"]
    volumes:
      - ./infrastructure/monitoring/otel-collector-config.yml:/etc/otel-collector-config.yml:ro
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter (scrape endpoint)
    environment:
      # Optional: Deployment environment (default: production)
      - ENVIRONMENT=${ENVIRONMENT:-production}
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=otel-collector
      - prometheus.io/scrape=true
      - prometheus.io/path=/metrics
      - prometheus.io/port=8888
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Grafana Tempo - Distributed tracing backend
  starbunk-tempo:
    image: grafana/tempo:latest
    container_name: starbunk-tempo
    restart: unless-stopped
    command: ["-config.file=/etc/tempo.yml"]
    volumes:
      - ./infrastructure/monitoring/tempo-config.yml:/etc/tempo.yml:ro
      # Optional: Data directory path (default: ./data)
      - ${UNRAID_APPDATA_PATH:-./data}/tempo:/tmp/tempo
    ports:
      - "3200:3200"   # Tempo HTTP API
      - "4317"        # OTLP gRPC receiver (internal)
      - "4318"        # OTLP HTTP receiver (internal)
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=tempo
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Prometheus - Metrics storage and querying
  starbunk-prometheus:
    image: prom/prometheus:latest
    container_name: starbunk-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./infrastructure/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      # Optional: Data directory path (default: ./data)
      - ${UNRAID_APPDATA_PATH:-./data}/prometheus:/prometheus
    ports:
      - "9090:9090"   # Prometheus web UI and API
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=prometheus
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Loki - Log aggregation system
  starbunk-loki:
    image: grafana/loki:latest
    container_name: starbunk-loki
    restart: unless-stopped
    command: ["-config.file=/etc/loki/loki-config.yml"]
    volumes:
      - ./infrastructure/monitoring/loki-config.yml:/etc/loki/loki-config.yml:ro
      # Optional: Data directory path (default: ./data)
      - ${UNRAID_APPDATA_PATH:-./data}/loki:/loki
    ports:
      - "3100:3100"   # Loki HTTP API
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=loki
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Promtail - Log collection agent
  starbunk-promtail:
    image: grafana/promtail:latest
    container_name: starbunk-promtail
    restart: unless-stopped
    command: ["-config.file=/etc/promtail/promtail-config.yml"]
    volumes:
      - ./infrastructure/monitoring/promtail-config.yml:/etc/promtail/promtail-config.yml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # Optional: Data directory path (default: ./data)
      - ${UNRAID_APPDATA_PATH:-./data}/promtail:/tmp
    networks:
      - starbunk-network
    depends_on:
      - starbunk-loki
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=promtail
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

# Note: Using host path mounts for Unraid compatibility
# Data persists in ${UNRAID_APPDATA_PATH:-./data}/ directory structure
# Default fallback to ./data/ for non-Unraid environments

# Custom network for service communication
networks:
  starbunk-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
