# =============================================================================
# ENVIRONMENT CONFIGURATION
# =============================================================================
NODE_ENV=production

# =============================================================================
# DISCORD BOT TOKENS
# =============================================================================
# Get tokens from: https://discord.com/developers/applications
# Each container uses its own Discord application/bot
# These are mapped to DISCORD_TOKEN in docker-compose.yml for each service

# REQUIRED: Discord bot token for BunkBot
BUNKBOT_TOKEN=your-bunkbot-token-here

# OPTIONAL: Discord bot token for DJCova (defaults to STARBUNK_TOKEN if not set)
DJCOVA_TOKEN=your-djcova-token-here

# OPTIONAL: Discord bot token for CovaBot (defaults to STARBUNK_TOKEN if not set)
COVABOT_TOKEN=your-covabot-token-here

# OPTIONAL: Discord bot token for BlueBot (defaults to STARBUNK_TOKEN if not set)
BLUEBOT_TOKEN=your-bluebot-token-here

# OPTIONAL: Fallback token for SnowBunk and other services
SNOWBUNK_TOKEN=your-snowbunk-token-here

# OPTIONAL: Fallback token for services that don't have their own token
STARBUNK_TOKEN=${SNOWBUNK_TOKEN}

# =============================================================================
# DISCORD APPLICATION CONFIGURATION
# =============================================================================
# REQUIRED: Primary Discord server/guild ID
GUILD_ID=your-guild-id-here

# Application/client ID is derived automatically from the bot token; no CLIENT_ID variable is needed.

# =============================================================================
# AI/LLM CONFIGURATION (CovaBot only)
# =============================================================================
# Ollama configuration (local LLM)
# For Docker: use http://ollama:11434 (if ollama is in docker-compose)
# For local development: use http://127.0.0.1:11434

# OPTIONAL: Ollama API URL (default: empty, disables Ollama if not set)
OLLAMA_API_URL=http://127.0.0.1:11434

# OPTIONAL: Chat model for generating responses (default: mistral:latest)
OLLAMA_MODEL=qwen2.5:7b

# OPTIONAL: Embedding model for semantic search/vector features (default: nomic-embed-text)
# Recommended: nomic-embed-text (768 dimensions, fast, good quality)
# Alternatives: mxbai-embed-large (1024d), all-minilm (384d, very fast)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# OPTIONAL: Automatically pull missing Ollama models at runtime (default: true)
# When enabled, if a model is not found, the bot will automatically download it
# This may take several minutes for large models but prevents manual intervention
OLLAMA_AUTO_PULL_MODELS=true

# OPTIONAL: Pull missing models on startup (default: true)
# When enabled, the bot will check for and start downloading the configured model during startup
# The download runs asynchronously and does not block the bot from starting to process messages
# Set to false if you want to pull models only on-demand (first 404 error)
OLLAMA_PULL_ON_STARTUP=true

# OPTIONAL: Timeout for model pull operations in milliseconds (default: 1200000 = 20 minutes)
# Large models (70B+) can be 40+ GB and may require longer timeouts
# Increase this value if you're pulling very large models on slow connections
OLLAMA_PULL_TIMEOUT_MS=1200000

# OPTIONAL: Scheduled model updates (default: true, weekly)
# When enabled, models are automatically updated on a regular schedule
# This ensures you have the latest model versions without manual intervention
OLLAMA_SCHEDULED_UPDATES=true

# OPTIONAL: Update interval in milliseconds (default: 604800000 = 7 days)
# Common values:
#   - 86400000 = 1 day (daily)
#   - 604800000 = 7 days (weekly) - recommended
#   - 2592000000 = 30 days (monthly)
OLLAMA_UPDATE_INTERVAL_MS=604800000

# =============================================================================
# DATABASE SERVICES CONFIGURATION
# =============================================================================
# These services are internal to the docker-compose stack (not exposed to host)
# They provide data persistence for the bots

# PostgreSQL - Relational database
# OPTIONAL: PostgreSQL username (default: starbunk)
POSTGRES_USER=starbunk

# OPTIONAL: PostgreSQL password (default: starbunk)
# IMPORTANT: Change this in production!
POSTGRES_PASSWORD=starbunk

# OPTIONAL: PostgreSQL database name (default: starbunk)
POSTGRES_DB=starbunk

# Redis - In-memory data store (social battery, caching)
# OPTIONAL: Redis hostname (default: starbunk-redis)
# Uses local Redis instance from docker-compose stack
# Only change if using external Redis server
REDIS_HOST=starbunk-redis

# OPTIONAL: Redis port (default: 6379)
REDIS_PORT=6379

# OPTIONAL: Redis password (default: empty, no auth)
# Set this for production deployments
REDIS_PASSWORD=

# OPTIONAL: Redis database number (default: 0)
REDIS_DB=0

# Qdrant - Vector database (saliency/interest matching)
# OPTIONAL: Qdrant URL (default: http://starbunk-vectordb:6333)
# Only change if using external Qdrant server
QDRANT_URL=http://starbunk-vectordb:6333

# OPTIONAL: Qdrant API key (default: empty, no auth)
# Set this for production deployments
QDRANT_API_KEY=

# =============================================================================
# OBSERVABILITY/MONITORING CONFIGURATION
# =============================================================================
# OPTIONAL: CovaBot web interface port (default: 7080)
COVABOT_WEB_PORT=7080

# Note: Bot metrics ports (9301-9304) are no longer exposed to the host.
# All observability data now flows through the OTEL collector.

# =============================================================================
# OBSERVABILITY CONFIGURATION (OpenTelemetry)
# =============================================================================
# All observability data (metrics, traces, logs) flows through the OTEL Collector
# The collector receives telemetry from bots and pushes to your remote observability stack
# (e.g., Unraid server with Prometheus, Loki, Tempo, Grafana)
#
# The OTEL collector is internal to the docker-compose stack (not exposed to host)
# Bots connect via internal network: http://starbunk-exporter:4317

# OPTIONAL: OTLP Collector hostname (default: starbunk-exporter)
# Only change if using external OTEL collector
OTEL_COLLECTOR_HOST=starbunk-exporter

# OPTIONAL: OTLP Collector HTTP port (default: 4318)
# Internal only - not exposed to host
OTEL_COLLECTOR_HTTP_PORT=4318

# OPTIONAL: OTLP Collector gRPC port (default: 4317)
# Internal only - not exposed to host
OTEL_COLLECTOR_GRPC_PORT=4317

# OPTIONAL: Enable/disable all observability (default: true)
OTEL_ENABLED=true

# =============================================================================
# REMOTE OBSERVABILITY STACK CONFIGURATION
# =============================================================================
# Configure these to point to your remote observability services
# (e.g., Unraid server, cloud provider, etc.)
# The OTEL collector will push telemetry data to these endpoints

# OPTIONAL: Observability host - Single IP/hostname for all services (default: localhost)
# Set to your Unraid server IP or external observability stack
# Example: OBSERVABILITY_HOST=192.168.1.100
OBSERVABILITY_HOST=localhost

# OPTIONAL: Service ports (usually don't need to change these)
PROMETHEUS_PORT=9090
LOKI_PORT=3100
TEMPO_PORT=4317

# =============================================================================
# GENERAL CONFIGURATION
# =============================================================================
# OPTIONAL: Deployment environment name (default: production)
ENVIRONMENT=production

# OPTIONAL: Logging level - trace, debug, info, warn, error, fatal (default: info)
LOG_LEVEL=info

# OPTIONAL: Internal metrics port (default: 3000)
# Services expose /metrics endpoint on this port for internal health checks
# All metrics flow to Prometheus via OTEL collector, not direct scraping
METRICS_PORT=3000

# =============================================================================
# DEBUG/TESTING CONFIGURATION (CovaBot only)
# =============================================================================
# OPTIONAL: Enable verbose debug logging and development behaviors (default: false)
# IMPORTANT FOR COVABOT: When DEBUG_MODE=true, CovaBot will ONLY respond to COVA_USER_ID
# This creates a calibration/testing mode where Cova can talk to the bot for testing
# Set to false for production deployment
DEBUG_MODE=false

# OPTIONAL: Discord user ID for Cova (used for debug mode filtering)
# In DEBUG_MODE, CovaBot will ONLY respond to this user ID
COVA_USER_ID=your-cova-user-id-here

# OPTIONAL: Comma-separated list of Discord server/guild IDs to restrict bot to (default: empty)
# When set, bot will ONLY process messages from these servers
# When empty, bot processes messages from any server
# Example: TESTING_SERVER_IDS=111111111111111111,222222222222222222
# Leave empty for production deployment to allow all servers
TESTING_SERVER_IDS=

# OPTIONAL: Comma-separated list of Discord channel IDs to restrict bot to (default: empty)
# When set, bot will ONLY process messages from these channels
# When empty, bot processes messages from any channel
# Example: TESTING_CHANNEL_IDS=1234567890,9876543210
TESTING_CHANNEL_IDS=

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
# OPTIONAL: Path for persistent data storage (default: ./data)
# For Unraid: set to /mnt/user/appdata/starbunk-js
# For local development: leave empty to use ./data
UNRAID_APPDATA_PATH=

# =============================================================================
# COVABOT CONFIGURATION
# =============================================================================
# OPTIONAL: CovaBot API key for web API authentication (default: empty, disables auth)
COVABOT_API_KEY=

