# =============================================================================
# ENVIRONMENT CONFIGURATION
# =============================================================================
NODE_ENV=production

# =============================================================================
# DISCORD BOT TOKENS
# =============================================================================
# Get tokens from: https://discord.com/developers/applications
# Each container uses its own Discord application/bot
# These are mapped to DISCORD_TOKEN in docker-compose.yml for each service

BUNKBOT_TOKEN=your-bunkbot-token-here
DJCOVA_TOKEN=your-djcova-token-here
COVABOT_TOKEN=your-covabot-token-here
BLUEBOT_TOKEN=your-bluebot-token-here
SNOWBUNK_TOKEN=your-snowbunk-token-here
# Fallback token for services that don't have their own token
STARBUNK_TOKEN=${SNOWBUNK_TOKEN}

# =============================================================================
# DISCORD APPLICATION CONFIGURATION
# =============================================================================
# Primary Discord server/guild ID
GUILD_ID=your-guild-id-here

# Client ID for DJCova (used for slash command registration)
CLIENT_ID=your-djcova-client-id-here

# =============================================================================
# AI/LLM CONFIGURATION (CovaBot only)
# =============================================================================
# Ollama configuration (local LLM)
# For Docker: use http://ollama:11434 (if ollama is in docker-compose)
# For local development: use http://127.0.0.1:11434
OLLAMA_API_URL=http://127.0.0.1:11434

# Chat model (for generating responses)
OLLAMA_MODEL=qwen2.5:7b

# Embedding model (for semantic search/vector features)
# Recommended: nomic-embed-text (768 dimensions, fast, good quality)
# Alternatives: mxbai-embed-large (1024d), all-minilm (384d, very fast)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Automatically pull missing Ollama models at runtime (default: true)
# When enabled, if a model is not found, the bot will automatically download it
# This may take several minutes for large models but prevents manual intervention
OLLAMA_AUTO_PULL_MODELS=true

# Pull missing models on startup (default: true)
# When enabled, the bot will check for and start downloading the configured model during startup
# The download runs asynchronously and does not block the bot from starting to process messages
# Set to false if you want to pull models only on-demand (first 404 error)
OLLAMA_PULL_ON_STARTUP=true

# Timeout for model pull operations in milliseconds (default: 1200000 = 20 minutes)
# Large models (70B+) can be 40+ GB and may require longer timeouts
# Increase this value if you're pulling very large models on slow connections
OLLAMA_PULL_TIMEOUT_MS=1200000

# Scheduled model updates (default: enabled, weekly)
# When enabled, models are automatically updated on a regular schedule
# This ensures you have the latest model versions without manual intervention
OLLAMA_SCHEDULED_UPDATES=true

# Update interval in milliseconds (default: 604800000 = 7 days)
# Common values:
#   - 86400000 = 1 day (daily)
#   - 604800000 = 7 days (weekly) - recommended
#   - 2592000000 = 30 days (monthly)
OLLAMA_UPDATE_INTERVAL_MS=604800000

# =============================================================================
# OBSERVABILITY/MONITORING CONFIGURATION
# =============================================================================
# Service ports for Prometheus scraping (host-side ports)
# These are the ports exposed on the host machine for external access
BUNKBOT_METRICS_PORT=9301
COVABOT_METRICS_PORT=9303
COVABOT_WEB_PORT=7080
DJCOVA_METRICS_PORT=9304
BLUEBOT_METRICS_PORT=9302

# =============================================================================
# OBSERVABILITY CONFIGURATION (OpenTelemetry)
# =============================================================================
# All observability data (metrics, traces, logs) flows through the OTLP Collector
# The collector then routes to Prometheus (metrics), Tempo (traces), and Loki (logs)

# OTLP Collector Endpoint (single endpoint for all observability data)
# For local development: use 'localhost'
# For Docker: use the service name 'otel-collector'
OTEL_COLLECTOR_HOST=otel-collector
OTEL_COLLECTOR_HTTP_PORT=4318
OTEL_COLLECTOR_GRPC_PORT=4317

# Observability Control (single toggle for metrics, traces, and logs)
OTEL_ENABLED=true

# Service Configuration
ENVIRONMENT=production
LOG_LEVEL=info

# Metrics Endpoint Port (for backward compatibility with Prometheus scraping)
# Services expose /metrics endpoint on this port for direct Prometheus scraping
METRICS_PORT=3000

# =============================================================================
# DEBUG/TESTING CONFIGURATION (CovaBot only)
# =============================================================================
# DEBUG_MODE: Enable verbose debug logging and development behaviors (true/false)
# IMPORTANT FOR COVABOT: When DEBUG_MODE=true, CovaBot will ONLY respond to COVA_USER_ID
# This creates a calibration/testing mode where Cova can talk to the bot for testing
# Set to false for production deployment
DEBUG_MODE=false

# COVA_USER_ID: Discord user ID for Cova (used for debug mode filtering)
# In DEBUG_MODE, CovaBot will ONLY respond to this user ID
COVA_USER_ID=your-cova-user-id-here

# TESTING_SERVER_IDS: Comma-separated list of Discord server/guild IDs to restrict bot to
# When set, bot will ONLY process messages from these servers
# When empty, bot processes messages from any server
# Example: TESTING_SERVER_IDS=111111111111111111,222222222222222222
# Leave empty for production deployment to allow all servers
TESTING_SERVER_IDS=

# TESTING_CHANNEL_IDS: Comma-separated list of Discord channel IDs to restrict bot to
# When set, bot will ONLY process messages from these channels
# When empty, bot processes messages from any channel
# Example: TESTING_CHANNEL_IDS=1234567890,9876543210
TESTING_CHANNEL_IDS=

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
# Path for persistent data storage (used by docker-compose volumes)
# For Unraid: set to /mnt/user/appdata/starbunk-js
# For local development: leave empty to use ./data
UNRAID_APPDATA_PATH=

# =============================================================================
# COVABOT CONFIGURATION
# =============================================================================
# CovaBot API key (optional, for web API authentication)
COVABOT_API_KEY=

