version: '3.8'

services:
  # BunkBot - Next generation YAML-based reply bot system
  bunkbot:
    build:
      context: .
      dockerfile: src/bunkbot/Dockerfile
    image: ghcr.io/andrewgari/bunkbot:latest
    container_name: starbunk-bunkbot
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - DISCORD_TOKEN=${BUNKBOT_TOKEN}
      - GUILD_ID=${GUILD_ID}
      - BUNKBOT_BOTS_DIR=/app/config
      - METRICS_PORT=${METRICS_PORT:-3000}
      # OpenTelemetry Configuration
      - OTEL_COLLECTOR_HOST=${OTEL_COLLECTOR_HOST:-otel-collector}
      - OTEL_COLLECTOR_HTTP_PORT=${OTEL_COLLECTOR_HTTP_PORT:-4318}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Mount the bot configuration directory
      - ./config/bunkbot:/app/config:ro
    # No host ports exposed - all observability via OTEL collector
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=bunkbot
      - prometheus.io/scrape=true
      - prometheus.io/path=/metrics
      - prometheus.io/port=3000
      - com.centurylinklabs.watchtower.enable=true
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # DJCova - Music service
  djcova:
    build:
      context: .
      dockerfile: src/djcova/Dockerfile
    image: ghcr.io/andrewgari/djcova:latest
    container_name: starbunk-djcova
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - NODE_ENV=production
      - DISCORD_TOKEN=${DJCOVA_TOKEN:-${STARBUNK_TOKEN}}
      - CLIENT_ID=${DJCOVA_CLIENT_ID}
      - DEBUG_MODE=${DEBUG_MODE:-false}
      - TESTING_SERVER_IDS=${TESTING_SERVER_IDS:-}
      - TESTING_CHANNEL_IDS=${TESTING_CHANNEL_IDS:-}
      - HEALTH_PORT=${HEALTH_PORT:-3000}
      # OpenTelemetry Configuration
      - OTEL_COLLECTOR_HOST=${OTEL_COLLECTOR_HOST:-starbunk-otel-collector}
      - OTEL_COLLECTOR_HTTP_PORT=${OTEL_COLLECTOR_HTTP_PORT:-4318}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Configuration directory (read-only)
      - ./config/djcova:/app/config:ro
      # Data directories (read-write)
      - ${UNRAID_APPDATA_PATH:-./data}/djcova/cache:/app/cache
      - ${UNRAID_APPDATA_PATH:-./data}/djcova/temp:/tmp
    # No host ports exposed - all observability via OTEL collector
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=djcova
      - prometheus.io/scrape=true
      - prometheus.io/path=/metrics
      - prometheus.io/port=3000
      - com.centurylinklabs.watchtower.enable=true
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # CovaBot - AI personality bot (Cognitive Simulacrum)
  covabot:
    build:
      context: .
      dockerfile: src/covabot/Dockerfile
    image: ghcr.io/andrewgari/covabot:latest
    container_name: starbunk-covabot
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=--max-old-space-size=768
      - DISCORD_TOKEN=${COVABOT_TOKEN:-${STARBUNK_TOKEN}}
      # LLM Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_DEFAULT_MODEL=${OPENAI_DEFAULT_MODEL:-gpt-4o-mini}
      - OLLAMA_API_URL=${OLLAMA_API_URL:-}
      - OLLAMA_DEFAULT_MODEL=${OLLAMA_DEFAULT_MODEL:-mistral:latest}
      - OLLAMA_AUTO_PULL_MODELS=${OLLAMA_AUTO_PULL_MODELS:-true}
      - OLLAMA_PULL_ON_STARTUP=${OLLAMA_PULL_ON_STARTUP:-true}
      - OLLAMA_PULL_TIMEOUT_MS=${OLLAMA_PULL_TIMEOUT_MS:-1200000}
      # Redis Configuration (Social Battery) - external endpoint
      # Note: Use host.docker.internal to access services on the Docker host
      - REDIS_HOST=${REDIS_HOST:-host.docker.internal}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - REDIS_DB=${REDIS_DB:-0}
      # Qdrant Configuration (Saliency/Interest Matching) - external endpoint
      # Note: Use host.docker.internal to access services on the Docker host
      - QDRANT_URL=${QDRANT_URL:-http://host.docker.internal:6333}
      - QDRANT_API_KEY=${QDRANT_API_KEY:-}
      # Storage Configuration
      - COVABOT_DATA_DIR=/app/data
      - COVABOT_API_KEY=${COVABOT_API_KEY:-}
      # Debug/Testing
      - DEBUG_MODE=${DEBUG_MODE:-false}
      - HEALTH_PORT=3000
      # OpenTelemetry Configuration
      - OTEL_COLLECTOR_HOST=${OTEL_COLLECTOR_HOST:-otel-collector}
      - OTEL_COLLECTOR_HTTP_PORT=${OTEL_COLLECTOR_HTTP_PORT:-4318}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Configuration directory (read-only)
      - ./config/covabot:/app/config:ro
      # Data directory for personality notes (read-write)
      - ${UNRAID_APPDATA_PATH:-./data}/covabot:/app/data
    ports:
      - "${COVABOT_WEB_PORT:-7080}:7080"
      # No metrics port exposed - all observability via OTEL collector
    networks:
      - starbunk-network
    extra_hosts:
      # Required for host.docker.internal to work on Linux
      - "host.docker.internal:host-gateway"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=covabot
      - prometheus.io/scrape=true
      - prometheus.io/path=/metrics
      - prometheus.io/port=3000
      - com.centurylinklabs.watchtower.enable=true
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # BlueBot - Blue detection and response bot
  bluebot:
    build:
      context: .
      dockerfile: src/bluebot/Dockerfile
    image: ghcr.io/andrewgari/bluebot:latest
    container_name: starbunk-bluebot
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - NODE_ENV=production
      - DISCORD_TOKEN=${BLUEBOT_TOKEN:-${STARBUNK_TOKEN}}
      - HEALTH_PORT=3000
      # OpenTelemetry Configuration
      - OTEL_COLLECTOR_HOST=${OTEL_COLLECTOR_HOST:-starbunk-otel-collector}
      - OTEL_COLLECTOR_HTTP_PORT=${OTEL_COLLECTOR_HTTP_PORT:-4318}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Configuration directory (read-only)
      - ./config/bluebot:/app/config:ro
    # No host ports exposed - all observability via OTEL collector
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=bluebot
      - prometheus.io/scrape=true
      - prometheus.io/path=/metrics
      - prometheus.io/port=3000
      - com.centurylinklabs.watchtower.enable=true
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # OpenTelemetry Collector - Unified telemetry pipeline
  starbunk-otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: starbunk-otel-collector
    restart: unless-stopped
    command: ["--config=/etc/otel-collector-config.yml"]
    volumes:
      - ./infrastructure/monitoring/otel-collector-config.yml:/etc/otel-collector-config.yml:ro
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter (scrape endpoint)
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=otel-collector
      - prometheus.io/scrape=true
      - prometheus.io/path=/metrics
      - prometheus.io/port=8888
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Grafana Tempo - Distributed tracing backend
  starbunk-tempo:
    image: grafana/tempo:latest
    container_name: starbunk-tempo
    restart: unless-stopped
    command: ["-config.file=/etc/tempo.yml"]
    volumes:
      - ./infrastructure/monitoring/tempo-config.yml:/etc/tempo.yml:ro
      - ${UNRAID_APPDATA_PATH:-./data}/tempo:/tmp/tempo
    ports:
      - "3200:3200"   # Tempo HTTP API
      - "4317"        # OTLP gRPC receiver (internal)
      - "4318"        # OTLP HTTP receiver (internal)
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=tempo
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Prometheus - Metrics storage and querying
  starbunk-prometheus:
    image: prom/prometheus:latest
    container_name: starbunk-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./infrastructure/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ${UNRAID_APPDATA_PATH:-./data}/prometheus:/prometheus
    ports:
      - "9090:9090"   # Prometheus web UI and API
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=prometheus
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Loki - Log aggregation system
  starbunk-loki:
    image: grafana/loki:latest
    container_name: starbunk-loki
    restart: unless-stopped
    command: ["-config.file=/etc/loki/loki-config.yml"]
    volumes:
      - ./infrastructure/monitoring/loki-config.yml:/etc/loki/loki-config.yml:ro
      - ${UNRAID_APPDATA_PATH:-./data}/loki:/loki
    ports:
      - "3100:3100"   # Loki HTTP API
    networks:
      - starbunk-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - com.starbunk.service=loki
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

# Note: Using host path mounts for Unraid compatibility
# Data persists in ${UNRAID_APPDATA_PATH:-./data}/ directory structure
# Default fallback to ./data/ for non-Unraid environments

# Custom network for service communication
networks:
  starbunk-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
